import google.generativeai as genai
from LLM.LLM import LLM

class Gemini(LLM):
    def configure_api(self):
        """
        Configures the Gemini API with the provided API key.
        """
        try:
            genai.configure(api_key=self.api_key)
        except Exception as e:
            print(f"Error configuring Gemini API: {e}")

    def get_response(self, prompt):
        """
        Calls the Gemini API with the given prompt and returns the response.

        Args:
            prompt: The prompt for the Gemini model.

        Returns:
            str: The response generated by the Gemini model.
        """
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"Error: {e}")
            return None


#Example usage
# import os
# from dotenv import load_dotenv

# load_dotenv()
# gemini = Gemini(os.environ["GEMINI_API_KEY"]) 

# # Configure the Gemini API with the provided API key.
# gemini.configure_api()

# # Now, use the `get_response` method to get a response for a given prompt.
# prompt = "What are the latest trends in artificial intelligence?"
# response = gemini.get_response(prompt)

# # Print the response from Gemini API.
# if response:
#     print("Response from Gemini:", response)
# else:
#     print("Failed to get a response.")